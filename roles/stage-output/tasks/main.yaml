- name: Register sources
  stat:
    path: "{{ item.key }}"
  with_dict: "{{ zuul_copy_output }}"
  register: sources

- name: Output a warning when input is not a dict and not empty
  debug:
    msg: "WARNING: extensions_to_txt is a list, values defined by parents will be overwritten"
  when:
    - extensions_to_txt is not mapping
    - extensions_to_txt

- name: Build the extensions list when input is not a dict (including empty)
  set_fact:
    extension_list: >
      {% set extensions = ['__does_not_match__'] -%}
      {% if extensions_to_txt -%}
        {% set extensions = extensions_to_txt -%}
      {% endif -%}
      {{- extensions -}}
  when: extensions_to_txt is not mapping

- name: Build the extensions list when input is a dict
  set_fact:
    extension_list: >
      {% set extensions = [] -%}
      {% for extension, extension_bool in extensions_to_txt.items() -%}
        {% if extension_bool -%}
          {% set _ = extensions.append(extension) -%}
        {% endif -%}
      {% endfor -%}
      {{- extensions -}}
  when: extensions_to_txt is mapping

- name: Build the extensions regular expression
  set_fact:
    extensions_regex: "{{ extension_list | join('|') }}"

# TODO(andreaf) We might want to enforce that item.value is a valid value
# in docs, artifacts, logs. Null case already handled.
# We don't check if the item is a file before renaming, but it is not likely
# to have directories with log, yaml or conf extension.
- name: Set source and destination for files and folders
  set_fact:
    source: "{{ item.stat.path }}"
    dest: "{{ item.item.value }}/{{ item.stat.path|basename|regex_replace('\\.(' + extensions_regex + ')$', '_\\1.txt') }}"
    type: "{{ item.item.value }}"
  with_items: "{{ sources.results }}"
  when:
    - item.stat.exists
    - item.item.value
  register: results

- name: Build a list of source, dest dictionaries for text files
  set_fact:
    all_sources: "{{ results.results | selectattr('ansible_facts', 'defined') | map(attribute='ansible_facts') | list }}"

- name: ensure target folders exist
  become: true
  file:
    path: "{{ stage_dir }}/{{ item }}"
    state: directory
    owner: "{{ ansible_user }}"
  with_items:
    - docs
    - artifacts
    - logs

- name: Copy text files to staging folder
  # remote_src copy does not work recursively, synchronise is restricted by
  # zuul, using command
  command: cp -pRL {{ item.source}} {{ stage_dir }}/{{ item.dest }}
  with_items: "{{ all_sources }}"

# NOTE(andreaf) The ansible module does not support recursive archive, so
# using gzip is the only option here. The good bit is that gzip itself is
# almost idempotent, as it will not compress again files with .gz extension.
# gzip will however return 1 if any compressed file is encountered, so we
# must ignore that (there's no specific error code).
- name: Archive everything from docs sources
  shell: gzip --recursive --best {{ item.dest }} || true
  args:
    chdir: "{{ stage_dir }}"
  with_items: "{{ all_sources }}"
  when:
    - stage_compress_logs
    - item.type == 'logs'
